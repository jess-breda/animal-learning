"""
Model classes for running SSM-based model experiments. 
Experiments can be run on the cluster or locally, and 
all results will be saved to experiment directory on cup.

This class assumes that all data to be used for the experiment
and all data generated by the experiment will be saved to cup.

Written by Jess Breda 2024-06-24
"""

import pandas as pd
import numpy as np
import pickle
from pathlib import Path

import violmulti.utils.save_load as save_load
from violmulti.data.dataset_loader import DatasetLoader
from violmulti.features.design_matrix_generator_PWM import *
from violmulti.models.ssm_glm_hmm import SSMGLMHMM


class ExperimentController:
    def __init__(self, experiment_name):
        self.experiment_name = experiment_name
        print(f"ExperimentController: Starting {experiment_name} experiment")

        self.experiment_dir = save_load.get_experiment_dir(self.experiment_name)
        self.config = save_load.load_config_from_yaml(
            config_path=self.experiment_dir / "config.yaml"
        )
        self.experiment_runner = self.determine_experiment_runner()

    def determine_experiment_runner(self):
        """
        Given the experiment type from the config,
        determine which experiment runner to use.
        """

        runner_class = MAP_EXPERIMENT_TO_RUNNER.get(self.config["experiment_type"])

        if runner_class is None:
            raise ValueError(
                f"Unknown experiment type: {self.config['experiment_type']}"
            )

        print(f"ExperimentController: Running {runner_class} experiment")
        return runner_class(self.experiment_name, self.config)

    def run(self):
        self.experiment_runner.run_experiment()


class SSMExperimentRunner:

    def __init__(self, experiment_name, config):
        # Naming & Paths
        self.experiment_name = experiment_name
        self.experiment_dir = save_load.get_experiment_dir(self.experiment_name)
        self.experiment_model_dir = self.experiment_dir / "models"
        self.experiment_data_dir = self.experiment_dir / "data"

        # Loading & Unpacking
        self.config = config
        self.unpack_and_format_config()
        self.raw_df = self.load_raw_data()

    def unpack_and_format_config(self):
        """
        Set up the config dictionary to be used in the experiment.
        This means unpacking any necessary attributes that are frequently
        used (e.g. animal_ids, model_config, dmg_config, etc.). As
        well as formatting the design matrix generator config since
        it utilizes lambda functions and these need to be instantiated
        from the str yaml format.

        # TODO- unclear how this will work with model comparison
        # TODO if we have multiple DMGs?
        """
        # Unpack
        self.animal_ids = self.config["animal_ids"]
        self.model_config = self.config["model_config"]

        # Format (lambda functions)
        self.dmg_config = save_load.convert_dmg_config_functions(
            self.config["dmg_config"]
        )

    def load_raw_data(self) -> pd.DataFrame:
        """
        Load the raw data to be passed into the DesignMatrixGenerator
        given configuration. All animals loaded into a single pandas
        dataframe with "animal_id" column that can be used for
        later grouping. See DatasetLoader for more details.

        Note data_tpe is almost always "new_trained" and this means
        use the newest version of the dataset and only trained data.
        """

        return DatasetLoader(
            animal_ids=self.config["animal_ids"],
            data_type=self.config["data_type"],
            data_path=str(save_load.determine_path_to_cup_data()),
        ).load_data()

    def generate_design_matrix(
        self, source_df: pd.DataFrame, dmg_config: dict
    ) -> tuple[pd.DataFrame, np.ndarray]:
        """
        General purpose method for generating the design matrix
        and labels for the experiment. This method should be
        inherited and used by the specific experiment runner.
        """

        dmg = DesignMatrixGeneratorPWM(source_df, dmg_config, verbose=True)

        X, y = dmg.create()  # N total trials long

        return X, y

    def fit_model(
        self, model_config: dict, Xs: np.ndarray, ys: np.ndarray
    ) -> Tuple[SSMGLMHMM, np.ndarray]:
        """
        General purpose method for fitting the model to
        the data. This method should be inherited and used
        by the specific experiment runner
        """
        model = SSMGLMHMM(model_config)
        log_ps = model.fit(Xs, ys)

        return model, log_ps

    @staticmethod
    def _assert_not_comparison_config(config: dict):
        """
        Assert that the config is not intended for comparison
        of multiple design matrices or models. The experiment
        runner being used is intended for fitting a single model
        with a single design matrix.

        This is indicated by having a nested dmg or model config
        with the model_names as first level keys that include
        "COMP" in the name.
        """
        assert len(config) > 0, "The dictionary is empty"
        first_key = next(iter(config))
        assert (
            "COMP" not in first_key
        ), f"Multi-model comparison config not allowed for this runner!"


class MegaFitExperimentRunner(SSMExperimentRunner):

    def __init__(self, experiment_name, config):
        super().__init__(experiment_name, config)

        # Check configs for MegaFit
        self._check_dmg_config()
        self._check_model_config()

    def _check_dmg_config(self):
        """
        Assumes that the dmg config is for a single design matrix
        generator. This is because MegaFit is intended to fit a
        single model to all animals- not compare multiple different
        design matrices.
        """
        self._assert_not_comparison_config(self.dmg_config)

    def _check_model_config(self):
        """
        Assumes model config is for a single model. Additionally,
        checks to makes sure appropriate keys are present in the
        model config for MegaFit.
        """
        self._assert_not_comparison_config(self.model_config)

        required_keys = ["n_inits", "n_states", "n_features", "n_categories"]
        for key in required_keys:
            assert key in self.model_config, f"Missing key in model config: {key}"

    def prepare_data_for_experiment(self):
        """
        For Mega Fit, the data prep is quite simple- data for all
        animals is prepared into a single dataframe with labels,
        these are saved out and then partitioned by session for
        the EM algorithm.

        """
        X, y = self.generate_design_matrix(
            source_df=self.raw_df,
            dmg_config=self.dmg_config,
        )
        save_load.save_data_and_labels_to_parquet(
            X,
            y,
            animal_id="Ws",
            model_name="mega_glmhmm",
            n_fold=0,
            data_path=self.experiment_data_dir,
        )
        Xs, ys = partition_data_by_session_for_EM(X, y)  # Jagged arrays N sessions long

        return Xs, ys

    def fit_model_for_experiment(self, Xs, ys):
        """
        The Mega Fit, the model fitting is also quite simple- the
        unique feature is iterating over the number of inits and
        saving out the model for each init and final summary stats
        at the end.
        """

        log_likelihoods = []
        log_posteriors = []

        for n_init in range(self.model_config["n_inits"]):
            print(f"\nMegaFitRunner: ****** Fitting init {n_init} ******")

            model, log_ps = super().fit_model(self.model_config, Xs, ys)
            save_load.save_model_to_pickle(
                model,
                animal_id="Ws",
                model_name="mega_glmhmm",
                n_fold=0,
                n_init=n_init,
                model_path=self.experiment_model_dir,
            )

            log_posteriors.append(log_ps)  # likelihood + prior
            log_likelihoods.append(model.log_likelihood(ys, Xs))

            # save out summary stats over iterations
            np.save(
                self.experiment_model_dir / "log_likelihoods.npy",
                np.array(log_likelihoods, dtype=object),
            )
            np.save(
                self.experiment_model_dir / "log_posteriors.npy",
                np.array(log_posteriors, dtype=object),
            )

    def run_experiment(self):

        # <=== Data Prep ==> Single DMG for all Animals
        Xs, ys = self.prepare_data_for_experiment()
        print("MegaFitRunner: Data Prep Complete")

        # <=== Model Fitting ==> Fit Model for N inits
        self.fit_model_for_experiment(Xs, ys)
        print("\nMegaFitRunner: Model Fit Complete")


MAP_EXPERIMENT_TO_RUNNER = {
    "mega_fit": MegaFitExperimentRunner,
}
