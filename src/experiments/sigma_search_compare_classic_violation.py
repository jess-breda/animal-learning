import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from collections import Counter
import matplotlib.pyplot as plt
import seaborn as sns

from src.model.multi_class_logistic_regression import MultiClassLogisticRegression
from src.model.exp_filter import ExpFilter
from src.data.get_rat_data import get_rat_viol_data


class DesignMatrixGeneratorCompareClassicViolation:
    def __init__(self, animal_id, verbose=True):
        self.animal_id = animal_id
        self.verbose = verbose

    @staticmethod
    def normalize_column(col):
        return (col - col.mean()) / col.std()

    def generate_design_matrix(
        self,
        df,
        feature_mode,
        tau,
        return_labels=True,
        drop_session_column=False,
    ):
        """
        Function to generate flexibledesign matrix given a dataframe
        with violations tracked. In this case "base" means using the
        same regressors as Nick Roy did in Psytrack, but adjusted to
        take into account 3 choice options (L,R, Violation).

        here, we are adding prev_violation fileted given a specific
        tau for each animal that was previously searched

        N = number of trials
        D = number of features
        C = number of classes, in this case 3 (L, R, Violation)

        params
        ------
        df : pd.DataFrame
            dataframe with columns `s_a` `s_b` `session`, `violation`
            `correct_side` and `choice`, likely generated by
            get_rat_viol_data()
        tau : float
            tau for exponential filter for prev_violation column
        feature_mode : str
            model to use for generating design matrix either
            "basic" or "violation" or "violation_filtered"
        return_label : bool (default = True)
            whether to return one-hot encoded choice labels
        drop_session_column : bool (default = False)
            whether to drop 'session' column. should be set to
            false if doing session based train/test split
            following design matrix generation

        returns
        -------
        X : pd.DataFrame, shape (N, D + 1)
            design matrix with regressors for s_a, s_b,
            prev sound avg, correct side and choice info,
            normalized to standard normal with bias column added
        Y : np.ndarray, shape (N, C), where C = 3 if return_labels=True
            one-hot encoded choice labels for each trial as left,
            right or violation
        """
        # Initialize
        X = pd.DataFrame()
        stim_cols = ["s_a", "s_b"]
        X["session"] = df.session

        # Masks- if first trial in a session and/or previous trial
        # was a violation, "prev" variables get set to 0
        session_boundaries_mask = df["session"].diff() == 0
        X["prev_violation"] = (
            df["violation"].shift() * session_boundaries_mask
        ).fillna(0)
        prev_violation_mask = X["prev_violation"] == 0

        # # Violation Exp Filter
        if feature_mode == "violation_filtered":
            self.exp_filter = ExpFilter(
                tau=tau, verbose=self.verbose, column="prev_violation"
            )
            self.exp_filter.apply_filter_to_dataframe(X)
            X.drop(columns=["prev_violation"], inplace=True)

        # Stimuli (s_a, s_b) get normalized
        for col in stim_cols:
            X[stim_cols] = self.normalize_column(df[stim_cols])

        # Average previous stimulus (s_a, s_b) loudness
        X["prev_sound_avg"] = df[stim_cols].shift().mean(axis=1)
        X["prev_sound_avg"] = self.normalize_column(X["prev_sound_avg"])
        X["prev_sound_avg"] *= session_boundaries_mask * prev_violation_mask

        # Prev correct side (L, R) (0, 1) -> (-1, 1),
        X["prev_correct"] = (
            df.correct_side.replace({0: -1}).astype(int).shift()
            * session_boundaries_mask
            * prev_violation_mask
        )

        # prev choice regressors (L, R, V) (0, 1, Nan) -> (-1, 1, 0),
        X["prev_choice"] = (
            df.choice.replace({0: -1}).fillna(0).astype(int).shift()
            * session_boundaries_mask
        )

        if feature_mode == "base":
            X.drop(columns=["prev_violation"], inplace=True)

        X.fillna(0, inplace=True)  # remove nan from shift()
        X.insert(0, "bias", 1)  # add bias column

        if drop_session_column:
            X.drop(columns=["session"], inplace=True)

        if return_labels:
            Y = self.one_hot_encode_labels(df)
            return X, Y
        else:
            return X

    @staticmethod
    def one_hot_encode_labels(df):
        """
        Function to one-hot encode choice labels for each trial as
        left, right or violation (C = 3)

        params
        ------
        df : pd.DataFrame
            dataframe with columns `choice` likely generated by
            get_rat_viol_data()

        returns
        -------
        Y : np.ndarray, shape (N, C), where C = 3
            one-hot encoded choice labels for each trial as left,
            right or violation
        """

        Y = pd.get_dummies(df["choice"], "choice", dummy_na=True).to_numpy(copy=True)
        return Y

    def get_train_test_sessions(self, df, test_size, random_state=45):
        """
        This function will return a list of sessions to use for training
        and testing respectively. To apply, see function
        see apply_session_train_test_split()


        Parameters:
        -----------
        df : pd.DataFrame
            dataframe with `sessions` column
        test_size : float
            Proportion of data to use for test set
        """
        unique_sessions = df["session"].unique()
        train_sessions, test_sessions = train_test_split(
            unique_sessions, test_size=test_size, random_state=random_state
        )

        self.train_sessions = train_sessions
        self.test_sessions = test_sessions
        self.random_state = random_state
        self.test_size = test_size

    def apply_session_train_test_split(self, X, Y):
        """
        train_sessions = np.array
            sessions for the
        test_values = np.array indices for the test values

        """
        # check if train/test sessions have been set
        if not hasattr(self, "train_sessions"):
            raise ValueError(
                "train_sessions and test_sessions have not been set. "
                "Please run get_train_test_sessions() first."
            )

        # Filter rows based on session values for X
        X_train = X[X["session"].isin(self.train_sessions)].copy()
        X_test = X[X["session"].isin(self.test_sessions)].copy()

        # Filter rows based on session values for Y
        # Assuming the index of Y corresponds to that of X
        Y_train = Y[X["session"].isin(self.train_sessions).values]
        Y_test = Y[X["session"].isin(self.test_sessions).values]

        X_train.drop(columns=["session"], inplace=True)
        X_test.drop(columns=["session"], inplace=True)

        self.X_train = X_train
        self.X_test = X_test
        self.Y_train = Y_train
        self.Y_test = Y_test

        return X_train, X_test, Y_train, Y_test

    def fit_null_model(self, animal_df):
        """
        Fits a null model and returns the log likelihood.

        Parameters:
        animal_df: DataFrame with choice and session data.

        Returns:
        float:
        """
        # Convert nan (violation) -> 2, L = 0, R =1
        choice = animal_df.choice.fillna(2)
        test_labels = choice[animal_df["session"].isin(self.test_sessions).values]

        # Count occurrences of each label
        label_counts = Counter(test_labels)

        # Calculate the total number of observations
        total_count = len(test_labels)

        # Calculate observed probabilities
        probabilities = {
            label: count / total_count for label, count in label_counts.items()
        }

        # Calculate the log-likelihood based on the observed probabilities
        log_likelihood = 0
        for label, prob in probabilities.items():
            log_likelihood += label_counts[label] * np.log(prob)
        return {
            "nll": -log_likelihood,
            "p_left": probabilities[0],
            "n_left": label_counts[0],
            "p_right": probabilities[1],
            "n_right": label_counts[1],
            "p_viol": probabilities[2],
            "n_viol": label_counts[2],
            "n_test_trials": total_count,
            "n_train_trials": len(animal_df) - total_count,
        }

    def store_null_info(self, animal_df):
        null_model = self.fit_null_model(animal_df)

        animal_info_df = pd.DataFrame(
            {
                "animal_id": [self.animal_id],
                "nll": [null_model["nll"]],
                "test_size": [self.test_size],
                "random_state": [self.random_state],
                "p_violation": [null_model["p_viol"]],
                "n_violation": [null_model["n_viol"]],
                "p_left": [null_model["p_left"]],
                "n_left": [null_model["n_left"]],
                "p_right": [null_model["p_right"]],
                "n_right": [null_model["n_right"]],
                "n_test_trials": [null_model["n_test_trials"]],
                "test_sessions": [self.test_sessions],
                "n_train_trials": [null_model["n_train_trials"]],
                "train_sessions": [self.train_sessions],
            }
        )
        # will be concat in experiment loop
        return animal_info_df


class SigmaSearchCompareClassicViolation:
    def __init__(self, params):
        self.animals = params["animals"]
        self.sigmas = params["sigmas"]
        self.model_names = params["model_names"]
        self.random_state = params["random_state"]
        self.test_size = params["test_size"]
        self.taus = self.get_taus()
        self.df = get_rat_viol_data(animal_ids=self.animals)
        self.stored_fits = []
        self.null_models = []

        if self.animals is None:
            self.animals = self.df.animal_id.unique()
        self.n_animals = len(self.animals)

    def run(self):
        for animal in self.animals:
            print(f"\n\n !!!!! evaluating animal {animal} !!!!!\n\n")
            if self.df.animal_id.nunique() > 1:
                # Load in data for specific animal
                animal_df = self.df.query("animal_id == @animal and training_stage > 2")
            else:
                animal_df = self.df.query("training_stage > 2")

            # Create a DesignMatrixGenerator object & get train/test sessions for animal
            dmg = DesignMatrixGeneratorCompareClassicViolation(
                verbose=False, animal_id=animal
            )
            dmg.get_train_test_sessions(
                animal_df, test_size=self.test_size, random_state=self.random_state
            )

            # store train/test info and null fit
            self.null_models.append(dmg.store_null_info(animal_df))

            # get tau for this animal
            tau = self.taus.query("animal_id == @animal")["tau"].values[0]

            # Iterate over sigma/tau combinations
            for sigma in self.sigmas:
                for model_name in self.model_names:
                    # Generate design matrix & create train/test splits
                    X, Y = dmg.generate_design_matrix(
                        animal_df,
                        tau=tau,
                        feature_mode=model_name,
                        return_labels=True,
                    )
                    print(
                        f"model : {model_name}, sigma: {sigma}, tau: {tau}, size of X: {X.shape}, Y: {Y.shape}"
                    )
                    (
                        X_train,
                        X_test,
                        Y_train,
                        Y_test,
                    ) = dmg.apply_session_train_test_split(X, Y)

                    # Fit model & evaluate
                    model = MultiClassLogisticRegression(sigma=sigma)
                    W_fit = model.fit(X_train, Y_train)
                    nll = model.eval(X_test, Y_test)

                    # Store model_fits
                    self.store(
                        animal,
                        model_name,
                        nll,
                        sigma,
                        tau,
                        W_fit,
                        dmg,
                    )

        self.model_fits = pd.concat(self.stored_fits, ignore_index=True)
        self.null_fits = pd.concat(self.null_models, ignore_index=True)
        return self.model_fits, self.null_fits

    def store(self, animal, model_name, nll, sigma, tau, W_fit, dmg):
        # Create a DataFrame for this iteration
        iter_df = pd.DataFrame(
            {
                "animal_id": [animal],
                "model_name": [model_name],
                "nll": [nll],
                "sigma": [sigma],
                "tau": [tau],
                "features": [list(dmg.X_test.columns)],
                "weights": [list(W_fit)],  # Convert numpy array to list
            }
        )
        # Append to the list of stored fits
        self.stored_fits.append(iter_df)

    ## WRANGLING ##

    def get_taus(self):
        """Load df with tau values for each animal
        that were found in macro sweep"""
        taus_df = pd.read_csv(
            "/Users/jessbreda/Desktop/github/animal-learning/data/results/prev_violation_tau.csv"
        )
        return taus_df

    def find_best_fit(self, group="model_name"):
        # if group is model name, will find the best sigma for
        # each tau tested.
        # if group is sigma, will find the best model name for
        # each sigma tested.

        best_fit_dfs = []

        for animal_id, sub_df in self.model_fits.groupby(["animal_id"]):
            best_idx = sub_df.groupby(group)["nll"].idxmin()
            best_fit_df = sub_df.loc[best_idx][
                ["animal_id", "model_name", "sigma", "tau", "nll"]
            ]
            best_fit_dfs.append(best_fit_df)

        return pd.concat(best_fit_dfs, ignore_index=True)

    def query_min_nll(self, animal_id, model_name):
        """
        Query the row with the minimum NLL for a given animal_id and model_name
        """
        query = self.model_fits.query(
            "animal_id == @animal_id and model_name == @model_name"
        ).sort_values(by="nll", ascending=True)

        return query.iloc[0]

    def compute_bits_per_trial_df(self):
        """
        Wrapper function to compute the number of bits per trial
        for each animal and model relative to the null model
        and return a dataframe with the results
        """
        combined_df = self._merge_null_and_fit_model_dfs()

        bits_per_trial_df = (
            combined_df.groupby("animal_id")
            .apply(self._calculate_bits_per_trial)
            .reset_index(drop=True)
        )

        self.bits_per_trial_df = bits_per_trial_df
        return bits_per_trial_df

    def _merge_null_and_fit_model_dfs(self):
        """
        Merge the null and model fit dataframes together
        with respect to negative log-like
        """

        # clean up dfs for concating
        self.null_fits["model_name"] = "null"
        best_fits = self.find_best_fit(
            group=["animal_id", "model_name"]
        )  # find best sigma for each animal, model

        # concat nll for null and fit models
        combined_df = pd.concat(
            [
                self.null_fits[["animal_id", "nll", "model_name"]],
                best_fits[["animal_id", "nll", "model_name"]],
            ]
        )

        # add in number of test trials for each animal
        combined_df = pd.merge(
            combined_df,
            self.null_fits[["animal_id", "n_test_trials"]],
            on="animal_id",
            how="left",
        )

        combined_df = pd.merge(
            combined_df, best_fits[["animal_id", "tau"]], on="animal_id", how="left"
        )

        # add in log-like (for easier bit calculation)
        combined_df["log_like"] = combined_df["nll"] * -1

        return combined_df

    def _calculate_bits_per_trial(self, group):
        """
        Calculate the number of bits per trial relative for each model
        relative to the null model (L_0) for each animal (group)

        bit/trial = (log model - log null model) / (n_test_trials * log(2))

        params
        ------
        group : pd.DataFrame
            groupby object with columns `animal_id`, `model_name`,
            `n_test_trials` and `ll` (log-likelihood)
            grouped by animal_id
        """
        bits_per_trial = []

        n_test_trials = group["n_test_trials"].iloc[
            0
        ]  # assumes each animal has same test size

        null_ll = group.query("model_name == 'null'")["log_like"].iloc[0]

        for _, row in group.iterrows():
            if row["model_name"] == "null":
                bits_per_trial.append((null_ll) / (n_test_trials * np.log(2)))
            else:
                bits_per_trial.append(
                    (row["log_like"] - null_ll) / (n_test_trials * np.log(2))
                )

        group["bits_per_trial"] = bits_per_trial
        return group

    ## PLOTTING ##

    def plot_nll_over_sigmas_by_animal(self, df=None):
        if df is None:
            df = self.find_best_fit(group="sigma")

        n_animals = df.animal_id.nunique()
        fig, ax = plt.subplots(
            n_animals, 1, figsize=(15, 5 * n_animals), sharex=True, sharey=True
        )

        df["is_min"] = df.groupby("animal_id")["nll"].transform(lambda x: x == x.min())

        if n_animals == 1:
            ax = [ax]

        for idx, (animal_id, sub_df) in enumerate(df.groupby("animal_id")):
            plt.xticks(rotation=90)

            current_ax = ax[idx] if n_animals > 1 else ax[0]

            sns.scatterplot(
                x="sigma",
                y="nll",
                data=sub_df,
                ax=current_ax,
                hue="is_min",
                palette=["grey", "red"],
            )

            # aesthetics
            plt.xticks(rotation=90)
            sns.despine()
            current_ax.legend().remove()
            current_ax.set(
                ylabel="Test NLL",
                title=f"Animal {animal_id}",
            )
            # if on the last plot, add the x-axis label
            if idx == n_animals - 1:
                current_ax.set(xlabel="Sigma")
            else:
                current_ax.set(xlabel="")

        return None

    def plot_class_weights(self, animal_id, model_name):
        """
        Wrapper function to plot class weights for a given animal and model
        """
        row = self.query_min_nll(animal_id, model_name)
        self._plot_class_weights(
            row["features"], np.array(row["weights"]), title=f"{animal_id} {model_name}"
        )

    def _plot_class_weights(self, feature_names, W_fit, title=""):
        """
        Internal function to plot the weights for each feature and class as bar charts.
        """
        D, C = W_fit.shape
        classes = ["L", "R", "V"]

        weight_data = [
            {"Weight": W_fit[d, c], "Feature": feature_names[d], "Class": classes[c]}
            for c in range(C)
            for d in range(D)
        ]
        df_weights = pd.DataFrame(weight_data)

        fig, ax = plt.subplots(figsize=(15, 6))
        ax.axhline(y=0, color="black")
        sns.barplot(x="Feature", y="Weight", hue="Class", data=df_weights, ax=ax)
        plt.xticks(rotation=45)
        plt.legend(loc="upper left")
        plt.title(title)

    def plot_model_comparison(
        self, type="point", hue=None, ax=None, ylim=None, **kwargs
    ):
        """
        Plot the model comparison for each animal
        """

        if ax is None:
            fig, ax = plt.subplots(figsize=(10, 5))

        if not hasattr(self, "bits_per_trial_df"):
            self.compute_bits_per_trial_df()

        if type == "point":
            sns.pointplot(
                data=self.bits_per_trial_df.query("model_name != 'null'"),
                x="model_name",
                y="bits_per_trial",
                hue=hue,
                ax=ax,
                **kwargs,
            )
        elif type == "bar":
            sns.barplot(
                data=self.bits_per_trial_df.query("model_name != 'null'"),
                x="model_name",
                y="bits_per_trial",
                hue=hue,
                ax=ax,
                **kwargs,
            )

        if hue == "animal_id":
            ax.legend().remove()
        if hue == "tau":
            ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)
        plt.xlabel("Model")
        plt.ylabel("Bits/Trial")

        if ylim is not None:
            ax.set(ylim=ylim)

        return None
