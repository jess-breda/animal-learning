"""
Design Matrix & Experiment class for comparing 
binary logistic regression model and multinomial 
logistic regression model where the multi-nomial
test set is the same two classes as the binary
test set.
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split

import pathlib
import sys

[
    sys.path.append(str(folder))
    for folder in pathlib.Path("../src/").iterdir()
    if folder.is_dir()
]

from exp_filter import ExpFilter
from null_model import NullModel
from binary_logistic_regression import BinaryLogisticRegression
from multiclass_logistic_regression import MultiClassLogisticRegression
from get_rat_data import get_rat_viol_data
from fitting_utils import get_train_test_sessions, get_taus


class DesignMatrixGeneratorBinaryMulti:
    def __init__(
        self, animal_id, train_sessions=None, test_sessions=None, verbose=True
    ):
        self.verbose = verbose
        self.animal_id = animal_id
        self.train_sessions = train_sessions
        self.test_sessions = test_sessions

    @staticmethod
    def normalize_column(col):
        return (col - col.mean()) / col.std()

    def generate_design_matrix(
        self,
        df,
        mode="binary",
        violations="none",
        tau=None,
        return_labels=True,
        drop_session_column=False,
    ):
        """
        Function to generate "base" design matrix given a dataframe
        with violations tracked. In this case "base" means using the
        same regressors as Nick Roy did in Psytrack.

        N = number of trials
        D = number of features

        params
        ------
        df : pd.DataFrame
            dataframe with columns `s_a` `s_b` `session`, `violation`
            `correct_side` and `choice`, likely generated by
            get_rat_viol_data()
        mode : str (default="binary")
            wether to use binary or multi-class logistic regression
        violations : str (default="none")
            whether to include violations as a regressor an if so,
            in what form ("prev", "exp" or "none")
        tau: float (default=None)
            if violations is "exp", tau is the time constant for
            the exponential filter (usually animal specific)
        return_label : bool (default = True)
            whether to return one-hot encoded choice labels
        drop_session_column : bool (default = False)
            whether to drop 'session' column. should be set to
            false if doing session based train/test split
            following design matrix generation

        returns
        -------
        X : pd.DataFrame, shape (N, D + 1)
            design matrix with regressors for s_a, s_b,
            prev sound avg, correct side and choice info,
            normalized to standard normal with bias column added
        Y : np.ndarray, shape (N, 3) if multi-class (N, ) if binary
            when return_labels=True.
        """
        # Initialize
        X = pd.DataFrame()
        stim_cols = ["s_a", "s_b"]
        X["session"] = df.session

        # Masks- if first trial in a session and/or previous trial
        # was a violation, "prev" variables get set to 0
        session_boundaries_mask = df["session"].diff() == 0
        X["prev_violation"] = (
            df["violation"].shift() * session_boundaries_mask
        ).fillna(0)
        prev_violation_mask = X["prev_violation"] == 0

        # # Violation Exp Filter
        if violations == "exp":
            self.exp_filter = ExpFilter(
                tau=tau, verbose=self.verbose, column="prev_violation"
            )
            self.exp_filter.apply_filter_to_dataframe(X)
            X.drop(columns=["prev_violation"], inplace=True)
        elif violations == "none":
            X.drop(columns=["prev_violation"], inplace=True)

        # Stimuli (s_a, s_b) get normalized
        for col in stim_cols:
            X[stim_cols] = self.normalize_column(df[stim_cols])

        # Average previous stimulus (s_a, s_b) loudness
        X["prev_sound_avg"] = df[stim_cols].shift().mean(axis=1)
        X["prev_sound_avg"] = self.normalize_column(X["prev_sound_avg"])
        X["prev_sound_avg"] *= session_boundaries_mask * prev_violation_mask

        # Prev correct side (L, R) (0, 1) -> (-1, 1),
        X["prev_correct"] = (
            df.correct_side.replace({0: -1}).astype(int).shift()
            * session_boundaries_mask
            * prev_violation_mask
        )

        # prev choice regressors (L, R, V) (0, 1, Nan) -> (-1, 1, 0),
        X["prev_choice"] = (
            df.choice.replace({0: -1}).fillna(0).astype(int).shift()
            * session_boundaries_mask
        )

        # if binary, drop the violation trials. if not using
        # prev violations, drop the prev_violation column as well
        if mode == "binary":
            X = X[df["violation"] != 1].reset_index(drop=True)
            # if violations != "prev":
            #     X.drop(columns=["prev_violation"], inplace=True)

        X.fillna(0, inplace=True)  # remove nan from shift()
        X.insert(0, "bias", 1)  # add bias column

        if drop_session_column:
            X.drop(columns=["session"], inplace=True)

        if return_labels:
            if mode == "binary":
                # make choice vector, drop nans (violations) to match X
                Y = df["choice"].dropna().astype(int).to_numpy()
            elif mode == "multi":
                Y = self.one_hot_encode_labels(df)
            return X, Y
        else:
            return X

    @staticmethod
    def one_hot_encode_labels(df):
        """
        Function to one-hot encode choice labels for each trial as
        left, right or violation (C = 3)

        params
        ------
        df : pd.DataFrame
            dataframe with columns `choice` likely generated by
            get_rat_viol_data()

        returns
        -------
        Y : np.ndarray, shape (N, C), where C = 3
            one-hot encoded choice labels for each trial as left,
            right or violation: [[1 0 0] , [0 1 0], [0 0 1]]
        """

        Y = pd.get_dummies(df["choice"], "choice", dummy_na=True).to_numpy(copy=True)
        return Y

    def apply_session_train_test_split(self, X, Y, filter_violations=False):
        """
        Function to apply train/test split to the design matrix. This function
        assumes that 1) the design matrix has a column called 'session' and 2)
        the train/test sessions have been defined when initializing the class,
        likely using src.models.fitting_utils.get_train_test_sessions().

        params
        ------
        X : pd.DataFrame, shape (N, D + 2)
            design matrix with bias column and session column
        Y : np.ndarray, shape (N, C) or (N, )
            one-hot encoded choice labels for mutli class (l, r, v) or
            binary class (l, r) respectively
        filter_violations : bool (default=False)
            whether to filter out violation trials from the test set
            for the multi-class case

        returns
        -------
        X_train : pd.DataFrame, shape (N_train, D + 1)
            design matrix for training set
        X_test : pd.DataFrame, shape (N_test, D + 1)
            design matrix for test set
        Y_train : np.ndarray, shape (N_train, C) or (N_train, )
            one-hot encoded  or binary encoded choice labels
            for training set
        Y_test : np.ndarray, shape (N_test, K) or (N_test, )
            on-hot encoded or binary encoded choice labels for
            test set. K = 2 if drop_violations=True, K = 3 otherwise
        """

        if not hasattr(self, "train_sessions"):
            raise ValueError("train_sessions and test_sessions not defined!")

        # Filter rows based on session values for X
        X_train = X[X["session"].isin(self.train_sessions)].copy()
        X_test = X[X["session"].isin(self.test_sessions)].copy()

        # Filter rows based on session values for Y
        # Assuming the index of Y corresponds to that of X
        Y_train = Y[X["session"].isin(self.train_sessions).values]
        Y_test = Y[X["session"].isin(self.test_sessions).values]

        X_train.drop(columns=["session"], inplace=True)
        X_test.drop(columns=["session"], inplace=True)

        self.X_train = X_train
        self.X_test = X_test
        self.Y_train = Y_train
        self.Y_test = Y_test

        # Additional code to filter out violations if flag is set
        if filter_violations:
            self.filter_violations_from_test_set()
            return (
                self.X_train,
                self.filtered_X_test,
                self.Y_train,
                self.filtered_Y_test,
            )

        return self.X_train, self.X_test, self.Y_train, self.Y_test

    def filter_violations_from_test_set(self):
        """
        Filters out the violation trials from Y_test and X_test. For
        the multi-class case to allow for comparision with the binary
        case on only L & R trials.

        Assumes that the violation is encoded as [0, 0, 1] in Y_test.
        """
        violation_filter = np.all(self.Y_test == np.array([0, 0, 1]), axis=1)
        non_violation_idx = np.where(~violation_filter)[0]

        self.filtered_Y_test = self.Y_test[non_violation_idx]
        self.filtered_X_test = self.X_test.iloc[non_violation_idx]


class ExperimentCompareBinaryMulti:
    def __init__(self, params):
        self.animals = params["animals"]
        self.sigmas = params["sigmas"]
        self.df = get_rat_viol_data(animal_ids=self.animals)
        self.taus = get_taus()
        self.random_state = params.get("random_state", 23)
        self.test_size = params.get("test_size", 0.2)
        self.null_models = []
        self.fit_models = pd.DataFrame(
            columns=[
                "animal_id",
                "model_name",
                "nll",
                "sigma",
                "tau",
                "features",
                "weights",
                "n_train_trials",
                "n_test_trials",
            ]
        )

        if self.animals is None:
            self.animals = self.df.animal_id.unique()
        self.n_animals = len(self.animals)

    def run(self):
        for animal_id in self.animals:
            print(f"\n\n !!!!! evaluating animal {animal_id} !!!!!\n\n")
            animal_df = self.df.query("animal_id == @animal_id and training_stage > 2")
            train_sessions, test_sessions = get_train_test_sessions(
                animal_df, self.test_size, self.random_state
            )
            self.run_single_animal(animal_id, animal_df, train_sessions, test_sessions)

        self.null_models = pd.concat(self.null_models, ignore_index=True)

        return

    def run_single_animal(self, animal_id, df, train_sessions, test_sessions):
        # compute the null model
        null_model = NullModel(test_sessions=test_sessions, mode="binary")
        self.null_models.append(null_model.compute_and_store(df))

        model_configs = self.get_model_configs()
        tau = self.taus.query("animal_id == @animal_id")["tau"].values[0]

        for sigma in self.sigmas:
            for model_name, config in model_configs.items():
                print(f"\nFitting {model_name} model with sigma {sigma}")

                # initialize design matrix generator with trian/test info
                dmg = DesignMatrixGeneratorBinaryMulti(
                    animal_id=animal_id,
                    train_sessions=train_sessions,
                    test_sessions=test_sessions,
                    verbose=False,
                )

                # generate design matrix given the mode & violation col pref
                X, y = dmg.generate_design_matrix(
                    df,
                    mode=model_name,  # binary or multi
                    violations=config["violations"],  # none, prev, exp
                    tau=tau,  # if violations = "exp" this will evaluate
                    return_labels=True,
                    drop_session_column=False,
                )

                # Apply train/test split. For  multi model,
                # violations are filtered out of test set
                X_train, X_test, y_train, y_test = dmg.apply_session_train_test_split(
                    X, y, filter_violations=config["filter_violations"]
                )

                # Initialize model, fit & store. Multi is only evaluated on l/r trials
                model = config["model_class"](sigma=sigma)
                W_fit = model.fit(X_train, y_train)
                nll = model.eval(X_test, y_test, lr_only=config["lr_only"])

                data = {
                    "animal_id": animal_id,
                    "model_name": model_name,
                    "nll": nll,
                    "sigma": sigma,
                    "tau": tau,
                    "features": X_test.columns,
                    "weights": W_fit,
                    "n_train_trials": len(X_train),
                    "n_test_trials": len(X_test),
                }

                self.store(data)

    def get_model_configs(self):
        """
        Function to return a dictionary of model configurations
        for a given animal. The dictionary keys are the model names
        and the values are specific variables that differ between the
        models. This is useful for running multiple models in a loop
        and changing only a few parameters.

        """
        return {
            "binary": {
                "model_class": BinaryLogisticRegression,
                "violations": "none",
                "filter_violations": False,
                "lr_only": None,
            },
            "multi": {
                "model_class": MultiClassLogisticRegression,
                "violations": "exp",
                "filter_violations": True,
                "lr_only": True,
            },
        }

    def store(self, data):
        """
        Function to store the fit information for a single
        animal and model sweep. This creates a single row of the
        self.fit_models data frame.

        params
        ------
        data : dict
            dictionary with keys `animal_id`, `model_name`, `nll`,
            `sigma`, `features`, `weights`, `n_train_trials` and
            `n_test_trials`
        """
        next_index = len(self.fit_models)
        for key, value in data.items():
            self.fit_models.loc[next_index, key] = value
        return None
